---
title: Deep Learning with Javascript 2.4-2.4.3
description: Notes on chapter two of Deep Learning with Javascript
---

<PageDescription>

Notes on chapter two of Deep Learning with Javascript

</PageDescription>


<AnchorLinks>
  <AnchorLink>2.4 How to Interpret Your Model</AnchorLink>
  <AnchorLink>2.4.1 Extracting Meaning from Learned Weights</AnchorLink>
  <AnchorLink>2.4.2 Extracting Internal Weights from the Model</AnchorLink>
  <AnchorLink>2.4.3 Caveats to Interpretability</AnchorLink>
</AnchorLinks>

## 2.4 How to Interpret Your Model

<InlineNotification>

**Goals**

1. Extract learned weights from a model
2. Interpret thos weights to weigh them against what one might think they should be


</InlineNotification>


### 2.4.1 Extracting Meaning from Learned Weights

The linear function example was _scalar_ however the features and the kernel here are both vectors
Here we are taking the _dot product_ of the two vectors.
```haskell
output = kernel Â· features + bias
```

This basically amounts to a relationship between the kernel and the features, where small learned values are learned to have little impact and and positive relationships increase predicted output and negative relationships decrease predicted output.

### 2.4.2 Extracting Internal Weights from the Model

Since this model has only one layer we can grab the output layer with the following 
```js
> model.layers[0]
```

Then we get the weights with the `getWeights()` since we're using a dense layer the returned array of weights will always have two elements the kernel and the bias..

We can access the tensor we're interested in with
```js
> model.layers[0].getWeights()[0]
```

We can access the contents of the tensor with a call to the `data()` function since its an async function we use the promised value as in the [previous post](/posts/202004010823--deep-learning-with-javascript-2.3.3--2.3.6#202004021821) marked as `kernelAsArray`


### 2.4.3 Caveats to Interpretability

If weights are different in a model for a feature that is included twice they can be switched around so we cannot say very much about this feature.
Correlation and causality must also be looked at carefully in order to avoid mistakes when making statements about features relationships to outputs...